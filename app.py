import streamlit as st
import asyncio
import edge_tts
import re
import io

# --- Page Configuration ---
st.set_page_config(page_title="Khmer SRT to Speech", page_icon="ğŸ™ï¸")

st.markdown("""
    <style>
    .stTextArea textarea { font-size: 16px !important; }
    .main { background-color: #f8f9fa; }
    .stButton>button { width: 100%; border-radius: 8px; height: 3em; background-color: #007bff; color: white; }
    </style>
    """, unsafe_allow_html=True)

## --- Logic Functions ---

def parse_srt(content):
    # Improved regex to handle various SRT line breaks and spacing
    pattern = re.compile(r'(\d+)\s*\n(\d{2}:\d{2}:\d{2},\d{3}) --> (\d{2}:\d{2}:\d{2},\d{3})\s*\n(.*?)(?=\n\n|\n\d+\n|$)', re.DOTALL)
    return pattern.findall(content)

async def process_segments(segments, voice_id):
    combined_audio = io.BytesIO()
    segment_data = []
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for i, (idx, start, end, txt) in enumerate(segments):
        clean_text = txt.replace('\n', ' ').strip()
        status_text.text(f"á€áŸ†á–á»á„áŠáŸ†áá¾ášá€á¶ášáƒáŸ’á›á¶á‘á¸ {idx}...")
        
        communicate = edge_tts.Communicate(clean_text, voice_id)
        audio_chunk = b""
        async for chunk in communicate.stream():
            if chunk["type"] == "audio":
                audio_chunk += chunk["data"]
        
        segment_data.append({"idx": idx, "audio": audio_chunk, "text": clean_text})
        combined_audio.write(audio_chunk)
        
        # Update progress
        progress_bar.progress((i + 1) / len(segments))
    
    status_text.text("á€á¶ášá”áŸ†á”áŸ’á›áŸ‚á„ááŸ’ášá¼áœá”á¶á“á”á‰áŸ’á…á”áŸ‹!")
    return segment_data, combined_audio.getvalue()

## --- UI Layout ---

st.title("ğŸ™ï¸ Khmer SRT Voice Generator")
st.info("á”áŸ†á”áŸ’á›áŸ‚á„á¯á€áŸá¶áš SRT ášá”áŸáŸ‹á¢áŸ’á“á€á‘áŸ…á‡á¶áŸáŸ†á¡áŸá„á¢á¶á“áŠáŸ„á™áŸáŸ’áœáŸá™á”áŸ’ášáœááŸ’áá·")

col1, col2 = st.columns([2, 1])

with col2:
    st.subheader("á€áŸ†áááŸ‹áŸáŸ†á¡áŸá„")
    voice_option = st.radio("á‡áŸ’ášá¾áŸášá¾áŸáŸáŸ†á¡áŸá„:", ["áŸáŸ’ášá¸á˜á»áŸ† (Sreymom)", "á–á·áŸá·áŠáŸ’á‹ (Piseth)"])
    voice_id = "km-KH-SreymomNeural" if "áŸáŸ’ášá¸á˜á»áŸ†" in voice_option else "km-KH-PisethNeural"

with col1:
    srt_input = st.text_area("á”á·á‘á—áŸ’á‡á¶á”áŸ‹á¢ááŸ’áá”á‘ SRT á“áŸ…á‘á¸á“áŸáŸ‡:", height=300, placeholder="1\n00:00:01,000 --> 00:00:04,000\náŸá½áŸáŸ’áá¸á”á„á”áŸ’á¢á¼á“á‘á¶áŸ†á„á¢áŸáŸ‹á‚áŸ’á“á¶...")

if st.button("ğŸš€ á…á¶á”áŸ‹á•áŸ’áá¾á˜á”áŸ†á”áŸ’á›áŸ‚á„"):
    if srt_input.strip():
        segments = parse_srt(srt_input)
        if segments:
            st.success(f"ášá€áƒá¾á‰á…áŸ†á“á½á“ {len(segments)} áƒáŸ’á›á¶")
            
            # Run the async processing
            all_segments, full_audio = asyncio.run(process_segments(segments, voice_id))
            
            # Master Download
            st.divider()
            st.subheader("ğŸ“ á‘á¶á‰á™á€á›á‘áŸ’á’á•á›ášá½á˜")
            st.audio(full_audio, format="audio/mp3")
            st.download_button("á‘á¶á‰á™á€ File ášá½á˜ (MP3)", full_audio, "full_audio.mp3", "audio/mp3")
            
            # Individual Segments
            with st.expander("á˜á¾á›á›á˜áŸ’á¢á·ááá¶á˜áƒáŸ’á›á¶á“á¸á˜á½á™áŸ—"):
                for item in all_segments:
                    st.write(f"áƒáŸ’á›á¶á‘á¸ {item['idx']}: {item['text']}")
                    st.audio(item['audio'], format="audio/mp3")
        else:
            st.error("á‘á˜áŸ’ášá„áŸ‹ SRT á˜á·á“ááŸ’ášá¹á˜ááŸ’ášá¼áœ! áŸá¼á˜á–á·á“á·ááŸ’á™á˜á¾á›á‘áŸ’ášá„áŸ‹á‘áŸ’ášá¶á™á–áŸá›áœáŸá›á¶ (00:00:00,000)")
    else:
        st.warning("áŸá¼á˜á”á‰áŸ’á…á¼á›á¢ááŸ’áá”á‘ SRT á‡á¶á˜á»á“áŸá·á“áŸ”")

